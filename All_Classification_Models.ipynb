{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "All_Classification_Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP5pbLbUaNvOWk81LkfW2AK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Varun0801/Deep_Learning-and-Machine_Learning_With_Python/blob/master/All_Classification_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v_-tJzZ1UNw",
        "outputId": "dac0419c-65f7-48d9-fe0b-142cb4ffce09"
      },
      "source": [
        "#importing the required libraries\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "#Reading the csv file\r\n",
        "data=pd.read_csv('cpdata.csv')\r\n",
        "print(data.head())\r\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   temperature   humidity        ph    rainfall label\n",
            "0    20.879744  82.002744  6.502985  202.935536  rice\n",
            "1    21.770462  80.319644  7.038096  226.655537  rice\n",
            "2    23.004459  82.320763  7.840207  263.964248  rice\n",
            "3    26.491096  80.158363  6.980401  242.864034  rice\n",
            "4    20.130175  81.604873  7.628473  262.717340  rice\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkJLwgf12APv",
        "outputId": "92f5c7df-c56d-4cf5-9f3e-f80e4275c9a5"
      },
      "source": [
        "#Creating dummy variable for target i.e label\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "# Initialize encoder object\r\n",
        "encoder = LabelEncoder()\r\n",
        "# Fit-transform on data\r\n",
        "data['label'] = encoder.fit_transform(data['label'])\r\n",
        "#label= pd.get_dummies(data.label).iloc[: , 1:]\r\n",
        "#data= pd.concat([data,label],axis=1)\r\n",
        "#data.drop('label', axis=1,inplace=True)\r\n",
        "print('The data present in one row of the dataset is')\r\n",
        "print(data.head())\r\n",
        "X = data.iloc[:,:-1]\r\n",
        "y =data.iloc[: ,-1]\r\n",
        "print(X.shape)\r\n",
        "print(y.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The data present in one row of the dataset is\n",
            "   temperature   humidity        ph    rainfall  label\n",
            "0    20.879744  82.002744  6.502985  202.935536     28\n",
            "1    21.770462  80.319644  7.038096  226.655537     28\n",
            "2    23.004459  82.320763  7.840207  263.964248     28\n",
            "3    26.491096  80.158363  6.980401  242.864034     28\n",
            "4    20.130175  81.604873  7.628473  262.717340     28\n",
            "(3100, 4)\n",
            "(3100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH34-UJF2JJd"
      },
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=6)\r\n",
        "\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "sc = StandardScaler()\r\n",
        "X_train = sc.fit_transform(X_train)\r\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n2SKsQo159g",
        "outputId": "a3cda03c-4eb6-46b0-d591-c51ed57a351d"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "\r\n",
        "#Four random models intitialised\r\n",
        "log_clf_1 = LogisticRegression(random_state=0)\r\n",
        "log_clf_2 = LogisticRegression(random_state=42)\r\n",
        "decision_clf1 = DecisionTreeClassifier(criterion = 'entropy',random_state=0)\r\n",
        "decision_clf2 = DecisionTreeClassifier(criterion = 'entropy', random_state=42)\r\n",
        "#Creating a list of models\r\n",
        "Model_List=[('Logistic Regression 1', log_clf_1),\r\n",
        "('Logistic Regression 2', log_clf_2),\r\n",
        "('Decision Tree 1', decision_clf1),\r\n",
        "('Decision Tree 2', decision_clf2)]\r\n",
        "\r\n",
        "#Initialising hard voting model\r\n",
        "voting_clf_hard = VotingClassifier(estimators = Model_List,voting = 'hard')\r\n",
        "#Fitting the data\r\n",
        "voting_clf_hard.fit(X_train, y_train)\r\n",
        "#Scoring the model for train\r\n",
        "hard_voting_score=voting_clf_hard.score(X_train,y_train)\r\n",
        "print(\"Hard Voting Train Accuracy:%.2f\"%hard_voting_score)\r\n",
        "#Scoring the model for test\r\n",
        "hard_voting_score=voting_clf_hard.score(X_test,y_test)\r\n",
        "print(\"Hard Voting Test Accuracy:%.2f\"%hard_voting_score)\r\n",
        "#Initialising soft voting model\r\n",
        "voting_clf_soft = VotingClassifier(estimators = Model_List,voting = 'soft')\r\n",
        "#Fitting the data\r\n",
        "voting_clf_soft.fit(X_train, y_train)\r\n",
        "#Scoring the model for train\r\n",
        "soft_voting_score= voting_clf_soft.score(X_train,y_train)\r\n",
        "print(\"Soft Voting Train Accuracy: %.2f\"%soft_voting_score)\r\n",
        "#Scoring the model for test\r\n",
        "soft_voting_score= voting_clf_soft.score(X_test,y_test)\r\n",
        "print(\"Soft Voting Test Accuracy: %.2f\"%soft_voting_score)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hard Voting Train Accuracy:0.88\n",
            "Hard Voting Test Accuracy:0.83\n",
            "Soft Voting Train Accuracy: 1.00\n",
            "Soft Voting Test Accuracy: 0.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0EloMeB2lYa",
        "outputId": "3c7f6435-7ddb-4bcb-ba75-7282b30292e7"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\r\n",
        "bagging_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=100, max_samples=100,\r\n",
        "random_state=0)\r\n",
        "#Fitting the data\r\n",
        "bagging_clf.fit(X_train, y_train)\r\n",
        "#Scoring the model for train data\r\n",
        "score_bc_dt = bagging_clf.score(X_train, y_train)\r\n",
        "print(\"Training score: %.2f \" % score_bc_dt)\r\n",
        "#Scoring the model for test data\r\n",
        "score_bc_dt = bagging_clf.score(X_test, y_test)\r\n",
        "print(\"Testing score: %.2f \" % score_bc_dt)\r\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training score: 0.90 \n",
            "Testing score: 0.88 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekMm41Aq3nKN",
        "outputId": "f1715840-712e-49c1-8f60-661bd9091b8f"
      },
      "source": [
        "pasting_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators=100 , max_samples=100, bootstrap=False, random_state=0)\r\n",
        "pasting_clf.fit(X_train,y_train)\r\n",
        "score_pasting = pasting_clf.score(X_test, y_test)\r\n",
        "print(score_pasting)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.867741935483871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "432I62FN39Yv",
        "outputId": "16f942e2-cc8d-44ed-e57b-6332a6f62503"
      },
      "source": [
        "pasting_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators=100 , max_samples=100, bootstrap=True, random_state=0)\r\n",
        "pasting_clf.fit(X_train,y_train)\r\n",
        "score_pasting = pasting_clf.score(X_test, y_test)\r\n",
        "print(score_pasting)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8790322580645161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjqkUXHp4BDV",
        "outputId": "1ffe06fd-a767-4ec5-dec6-b825ea853be2"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "rf_clf=RandomForestClassifier(n_estimators=100,n_jobs=100,random_state=0,min_samples_leaf=100)\r\n",
        "#Fitting on data\r\n",
        "rf_clf.fit(X_train, y_train)\r\n",
        "#Scoring the model on train data\r\n",
        "score_rf=rf_clf.score(X_train, y_train)\r\n",
        "print(\"Training score: %.2f \" % score_rf)\r\n",
        "#Scoring the model on test_data\r\n",
        "score_rf=rf_clf.score(X_test, y_test)\r\n",
        "print(\"Testing score: %.2f \" % score_rf)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training score: 0.78 \n",
            "Testing score: 0.74 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nz2aXrr4SNc",
        "outputId": "882753d4-9144-4bd2-c701-c69a0aac53aa"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "\r\n",
        "#Parameter grid\r\n",
        "parameter_grid = {\"max_depth\": [ 5, None],\r\n",
        "              \"max_features\": [ 4],\r\n",
        "              \"min_samples_split\": [5, 10],\r\n",
        "              \"min_samples_leaf\": [5, 10],\r\n",
        "              \"bootstrap\": [True, False],\r\n",
        "              \"criterion\": [\"gini\", \"entropy\"]}\r\n",
        "\r\n",
        "# Code starts here\r\n",
        "clf = RandomForestClassifier(random_state=0)\r\n",
        "grid_search = GridSearchCV(clf,param_grid =parameter_grid)\r\n",
        "grid_search.fit(X_train, y_train)\r\n",
        "score_gs = grid_search.score(X_test,y_test)\r\n",
        "print(score_gs)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9129032258064517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8Oh-2BK5Otq",
        "outputId": "0193e0a2-de05-46c2-e62e-bae6d800b8d2"
      },
      "source": [
        "from mlxtend.classifier import StackingClassifier\r\n",
        "\r\n",
        "classifier1 = DecisionTreeClassifier(random_state=0)\r\n",
        "classifier2= DecisionTreeClassifier(random_state=1)\r\n",
        "classifier3 = DecisionTreeClassifier(random_state=2)\r\n",
        "classifier4= DecisionTreeClassifier(random_state=3)\r\n",
        "classifier_list=[classifier1,classifier2,classifier3,classifier4]\r\n",
        "\r\n",
        "m_classifier=LogisticRegression(max_iter = 600,random_state=0)\r\n",
        "\r\n",
        "# Code starts here\r\n",
        "sclf = StackingClassifier(classifiers = classifier_list, meta_classifier = m_classifier)\r\n",
        "sclf.fit(X_train,y_train)\r\n",
        "s_score = sclf.score(X_test,y_test)\r\n",
        "print(s_score)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8919354838709678\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkRQls1C9y2m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}